{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data set\n",
    "diabetes_set = pd.read_csv('./diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x (feature matrix)\n",
    "x = diabetes_set.drop('Outcome', axis=1)\n",
    "\n",
    "# create y (label)\n",
    "y = diabetes_set['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose right model and hyperparameter\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model to the train dataset\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6428571428571429"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model on the test set\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5814332247557004"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model on the train set\n",
    "clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72        98\n",
      "           1       0.52      0.54      0.53        56\n",
      "\n",
      "    accuracy                           0.65       154\n",
      "   macro avg       0.62      0.62      0.62       154\n",
      "weighted avg       0.65      0.65      0.65       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70, 28],\n",
       "       [26, 30]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6493506493506493"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying model with hinge param_loss...\n",
      "Model accuracy on test set: 66.88%\n",
      "\n",
      "trying model with log param_loss...\n",
      "Model accuracy on test set: 36.36%\n",
      "\n",
      "trying model with modified_huber param_loss...\n",
      "Model accuracy on test set: 62.99%\n",
      "\n",
      "trying model with squared_hinge param_loss...\n",
      "Model accuracy on test set: 68.18%\n",
      "\n",
      "trying model with perceptron param_loss...\n",
      "Model accuracy on test set: 63.64%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# improve a model\n",
    "param_loss = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']\n",
    "\n",
    "np.random.seed(49)\n",
    "for i in param_loss:\n",
    "    print(f\"trying model with {i} param_loss...\")\n",
    "    clf = SGDClassifier(loss=i).fit(x_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {clf.score(x_test, y_test) *100:.2f}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying different model\n",
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7532467532467533"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82        98\n",
      "           1       0.74      0.50      0.60        56\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.75      0.70      0.71       154\n",
      "weighted avg       0.75      0.75      0.74       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluating model\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88, 10],\n",
       "       [28, 28]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7532467532467533"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying model with `linear` kernel_list...\n",
      "Model accuracy on test set: 77.92%\n",
      "\n",
      "trying model with `poly` kernel_list...\n",
      "Model accuracy on test set: 75.97%\n",
      "\n",
      "trying model with `rbf` kernel_list...\n",
      "Model accuracy on test set: 75.32%\n",
      "\n",
      "trying model with `sigmoid` kernel_list...\n",
      "Model accuracy on test set: 44.81%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# improve a model\n",
    "kernel_list = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "np.random.seed(42)\n",
    "for i in kernel_list:\n",
    "    print(f\"trying model with `{i}` kernel_list...\")\n",
    "    clf = svm.SVC(kernel=i).fit(x_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {clf.score(x_test, y_test) *100:.2f}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying different model (RandomForestClassifier)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model \n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((154,), (154,))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "y_preds = clf.predict(x_test)\n",
    "y_preds.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7922077922077922"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating model\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85        98\n",
      "           1       0.77      0.61      0.68        56\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.79      0.75      0.76       154\n",
      "weighted avg       0.79      0.79      0.79       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluating model\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[88, 10],\n",
       "       [22, 34]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7922077922077922"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying model with `10` n_estimators...\n",
      "Model accuracy (auto) on test set: 77.92%\n",
      "model  accuracy (hands on) : 77.92%\n",
      "\n",
      "trying model with `20` n_estimators...\n",
      "Model accuracy (auto) on test set: 81.17%\n",
      "model  accuracy (hands on) : 81.17%\n",
      "\n",
      "trying model with `30` n_estimators...\n",
      "Model accuracy (auto) on test set: 78.57%\n",
      "model  accuracy (hands on) : 78.57%\n",
      "\n",
      "trying model with `40` n_estimators...\n",
      "Model accuracy (auto) on test set: 76.62%\n",
      "model  accuracy (hands on) : 76.62%\n",
      "\n",
      "trying model with `50` n_estimators...\n",
      "Model accuracy (auto) on test set: 78.57%\n",
      "model  accuracy (hands on) : 78.57%\n",
      "\n",
      "trying model with `60` n_estimators...\n",
      "Model accuracy (auto) on test set: 77.27%\n",
      "model  accuracy (hands on) : 77.27%\n",
      "\n",
      "trying model with `70` n_estimators...\n",
      "Model accuracy (auto) on test set: 77.92%\n",
      "model  accuracy (hands on) : 77.92%\n",
      "\n",
      "trying model with `80` n_estimators...\n",
      "Model accuracy (auto) on test set: 77.92%\n",
      "model  accuracy (hands on) : 77.92%\n",
      "\n",
      "trying model with `90` n_estimators...\n",
      "Model accuracy (auto) on test set: 77.92%\n",
      "model  accuracy (hands on) : 77.92%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# improve\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"trying model with `{i}` n_estimators...\")\n",
    "    clf = GradientBoostingClassifier(n_estimators=i).fit(x_train, y_train)\n",
    "    print(f\"Model accuracy (auto) on test set: {clf.score(x_test, y_test) *100:.2f}%\")\n",
    "    print(f\"model  accuracy (hands on) : {accuracy_score(y_test, clf.predict(x_test) ) * 100:.2f}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open('GradientBoosting_model_1.pkl', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792207792207793"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "loaded_model = pickle.load(open(\"GradientBoosting_model_1.pkl\", \"rb\"))\n",
    "loaded_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data set\n",
    "diabetes_set = pd.read_csv('./diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split x, y\n",
    "x = diabetes_set.drop('Outcome', axis=1)\n",
    "y = diabetes_set['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.639947</td>\n",
       "      <td>0.848324</td>\n",
       "      <td>0.149641</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>0.204013</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>1.425995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-1.123396</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.530902</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-0.684422</td>\n",
       "      <td>-0.365061</td>\n",
       "      <td>-0.190672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.233880</td>\n",
       "      <td>1.943724</td>\n",
       "      <td>-0.263941</td>\n",
       "      <td>-1.288212</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-1.103255</td>\n",
       "      <td>0.604397</td>\n",
       "      <td>-0.105584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-0.998208</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>0.154533</td>\n",
       "      <td>0.123302</td>\n",
       "      <td>-0.494043</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>-1.041549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.141852</td>\n",
       "      <td>0.504055</td>\n",
       "      <td>-1.504687</td>\n",
       "      <td>0.907270</td>\n",
       "      <td>0.765836</td>\n",
       "      <td>1.409746</td>\n",
       "      <td>5.484909</td>\n",
       "      <td>-0.020496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>1.827813</td>\n",
       "      <td>-0.622642</td>\n",
       "      <td>0.356432</td>\n",
       "      <td>1.722735</td>\n",
       "      <td>0.870031</td>\n",
       "      <td>0.115169</td>\n",
       "      <td>-0.908682</td>\n",
       "      <td>2.532136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>-0.547919</td>\n",
       "      <td>0.034598</td>\n",
       "      <td>0.046245</td>\n",
       "      <td>0.405445</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>0.610154</td>\n",
       "      <td>-0.398282</td>\n",
       "      <td>-0.531023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.342981</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.149641</td>\n",
       "      <td>0.154533</td>\n",
       "      <td>0.279594</td>\n",
       "      <td>-0.735190</td>\n",
       "      <td>-0.685193</td>\n",
       "      <td>-0.275760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>0.159787</td>\n",
       "      <td>-0.470732</td>\n",
       "      <td>-1.288212</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-0.240205</td>\n",
       "      <td>-0.371101</td>\n",
       "      <td>1.170732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-0.844885</td>\n",
       "      <td>-0.873019</td>\n",
       "      <td>0.046245</td>\n",
       "      <td>0.656358</td>\n",
       "      <td>-0.692891</td>\n",
       "      <td>-0.202129</td>\n",
       "      <td>-0.473785</td>\n",
       "      <td>-0.871374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0       0.639947  0.848324       0.149641       0.907270 -0.692891  0.204013   \n",
       "1      -0.844885 -1.123396      -0.160546       0.530902 -0.692891 -0.684422   \n",
       "2       1.233880  1.943724      -0.263941      -1.288212 -0.692891 -1.103255   \n",
       "3      -0.844885 -0.998208      -0.160546       0.154533  0.123302 -0.494043   \n",
       "4      -1.141852  0.504055      -1.504687       0.907270  0.765836  1.409746   \n",
       "..           ...       ...            ...            ...       ...       ...   \n",
       "763     1.827813 -0.622642       0.356432       1.722735  0.870031  0.115169   \n",
       "764    -0.547919  0.034598       0.046245       0.405445 -0.692891  0.610154   \n",
       "765     0.342981  0.003301       0.149641       0.154533  0.279594 -0.735190   \n",
       "766    -0.844885  0.159787      -0.470732      -1.288212 -0.692891 -0.240205   \n",
       "767    -0.844885 -0.873019       0.046245       0.656358 -0.692891 -0.202129   \n",
       "\n",
       "     DiabetesPedigreeFunction       Age  \n",
       "0                    0.468492  1.425995  \n",
       "1                   -0.365061 -0.190672  \n",
       "2                    0.604397 -0.105584  \n",
       "3                   -0.920763 -1.041549  \n",
       "4                    5.484909 -0.020496  \n",
       "..                        ...       ...  \n",
       "763                 -0.908682  2.532136  \n",
       "764                 -0.398282 -0.531023  \n",
       "765                 -0.685193 -0.275760  \n",
       "766                 -0.371101  1.170732  \n",
       "767                 -0.473785 -0.871374  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Standard Scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_x = scaler.fit_transform(x)\n",
    "scaled_x = pd.DataFrame(scaled_x, columns=x.columns)\n",
    "scaled_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split x_train, x_test, y_train, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled_x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose right model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=20)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model \n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792207792207793"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating \n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "preds = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72, 28],\n",
       "       [38, 16]], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying model with `10` n_estimators...\n",
      "Model accuracy (auto) on test set: 77.92%\n",
      "\n",
      "trying model with `20` n_estimators...\n",
      "Model accuracy (auto) on test set: 77.92%\n",
      "\n",
      "trying model with `30` n_estimators...\n",
      "Model accuracy (auto) on test set: 76.62%\n",
      "\n",
      "trying model with `40` n_estimators...\n",
      "Model accuracy (auto) on test set: 78.57%\n",
      "\n",
      "trying model with `50` n_estimators...\n",
      "Model accuracy (auto) on test set: 77.27%\n",
      "\n",
      "trying model with `60` n_estimators...\n",
      "Model accuracy (auto) on test set: 77.92%\n",
      "\n",
      "trying model with `70` n_estimators...\n",
      "Model accuracy (auto) on test set: 77.27%\n",
      "\n",
      "trying model with `80` n_estimators...\n",
      "Model accuracy (auto) on test set: 78.57%\n",
      "\n",
      "trying model with `90` n_estimators...\n",
      "Model accuracy (auto) on test set: 78.57%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# improve\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "for i in range(10, 100, 10):\n",
    "    print(f\"trying model with `{i}` n_estimators...\")\n",
    "    clf = GradientBoostingClassifier(n_estimators=i).fit(x_train, y_train)\n",
    "    print(f\"Model accuracy (auto) on test set: {clf.score(x_test, y_test) *100:.2f}%\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
